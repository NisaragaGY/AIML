import numpy as np
import pylab as pl
from sklearn import datasets
from sklearn.tree import DecisionTreeRegressor

from sklearn.metrics import mean_absolute_error
from sklearn import datasets
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error,median_absolute_error,r2_score,mean_absolute_error
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split

def load_data():
    boston=datasets.boston()
    return boston
def explore_city_data(city_data):
    housing_prices=city_data.target
    housing_features=city_data.data
    number_of_houses=housing_features.shape[0]
    number_of_features=housing_features.shape[1]
    max_prices=np.max(housing_prices)
    min_prices=np.min(housing_prices)
    mean_prices=np.mean(housing_prices)
    median_prices=np.median(housing_prices)
    standard_deviation=np.std(housing_prices)
    print("number of houses",number_of_houses)
    print("number of features",number_of_features)
    print("max price of house",max_prices)
    print("min of houses",min_prices)
    print("meanprice of houses",mean_price)
    print("median of house",meadian_price)
    print("std of houses",standard_deviation)

def Performance_metric(label, prediction):
    return mean_squard_error(label, prediction)
pass

def split_data(city_data):
    x,y=city_data.data,city_data.target
    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,train_size=0.70,random_state=42)
    return x_train,y_train,x_test,y_test

def learning_curve(depth,x_train,y_train,x_test,y_test):
    sizes=np.linespace(1,len(x_train),50)
    train_err=np.zeros (len(sizes))
    test_err=np.zeros (len(sizes))
    print"Decision tree with max depth")
    print (Depth)
   